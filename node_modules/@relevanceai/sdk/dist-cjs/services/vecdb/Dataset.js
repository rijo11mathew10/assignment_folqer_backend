"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
exports.Dataset = void 0;
const _1 = require(".");
class Dataset {
    constructor(client, name, options) {
        // TODO validate name
        this.client = client;
        this.name = name;
        this.config = options || {};
    }
    get datasetName() {
        return this.name;
    }
    ;
    async createIfNotExist() {
        try {
            await this.client.apiClient.GetDatasetDetails({}, { dataset_id: this.name });
            return false;
        }
        catch (err) {
            await this.client.apiClient.CreateDataset({ id: this.name, ...(this.config.schema ? { schema: this.config.schema } : {}) });
            return true;
        }
    }
    async recreateIfExists() {
        try {
            await this.client.apiClient.GetDatasetDetails({}, { dataset_id: this.name });
            await this.client.apiClient.DeleteDataset({}, { dataset_id: this.name });
            await this.client.apiClient.CreateDataset({ id: this.name, ...(this.config.schema ? { schema: this.config.schema } : {}) });
            return true;
        }
        catch (err) {
            return false;
        }
    }
    async insertDocument(document, options) {
        const response = await this.client.apiClient.Insert({
            document,
            ...options
        }, { dataset_id: this.name });
        return response.body;
    }
    async search(...args) {
        let payload = {};
        let options = {};
        for (const arg of args) {
            if (arg instanceof _1._QueryBuilder) {
                payload = { ...payload, ...arg.build() };
            }
            else {
                options = arg;
                if (options.rawPayload)
                    payload = { ...payload, ...options.rawPayload };
            }
        }
        const reqCallback = async () => await this.client.apiClient.SimpleSearchPost(payload, { dataset_id: this.name });
        if (options.debounce && this.debounceTimer) {
            clearTimeout(this.debounceTimer);
            return new Promise((resolve) => {
                this.debounceTimer = setTimeout(async () => { const res = await reqCallback(); resolve(res); }, options.debounce);
            });
        }
        else {
            const response = await reqCallback();
            return response.body;
        }
    }
    async insertDocuments(documents, encoders, options) {
        const results = await this._GenericBulkOperation({
            data: documents !== null && documents !== void 0 ? documents : [],
            ...options,
            fn: async (documentsSlice) => (await this.client.apiClient.BulkInsert({ documents: documentsSlice, ...(encoders ? { encoders } : {}) }, { dataset_id: this.name })).body
        });
        const finalResults = results.reduce((prev, cur) => {
            prev.failed_documents = prev.failed_documents.concat(cur.failed_documents);
            prev.inserted += cur.inserted;
            return prev;
        }, { inserted: 0, failed_documents: [] });
        return finalResults;
    }
    // TODO - ChunkSearch, insert, insertAndVectorize?, vectorize, 
    async _GenericBulkOperation({ data, batchSize, fn, retryCount }) {
        batchSize = batchSize !== null && batchSize !== void 0 ? batchSize : 10000;
        retryCount = retryCount !== null && retryCount !== void 0 ? retryCount : 1;
        const results = [];
        for (let i = 0; i < (data === null || data === void 0 ? void 0 : data.length); i += batchSize) {
            for (let retrysSoFar = 0; retrysSoFar < retryCount; retrysSoFar++) {
                try {
                    const res = await fn(data.slice(i, i + batchSize));
                    results.push(res);
                    break;
                }
                catch (e) {
                    console.error(`Bulk operation failed with error, retrying - ${e}`);
                }
            }
        }
        return results;
    }
    async updateDocument(documentId, partialUpdates) {
        const response = await this.client.apiClient.Update({ id: documentId, updates: partialUpdates });
        return response.body;
    }
    async updateDocuments(updates, options) {
        const results = await this._GenericBulkOperation({
            data: updates !== null && updates !== void 0 ? updates : [],
            ...options,
            fn: async (updatesSlice) => (await this.client.apiClient.BulkUpdate({ updates: updatesSlice }, { dataset_id: this.name })).body
        });
        const finalResults = results.reduce((prev, cur) => {
            prev.failed_documents = prev.failed_documents.concat(cur.failed_documents);
            prev.inserted += cur.inserted;
            return prev;
        }, { inserted: 0, failed_documents: [] });
        return finalResults;
    }
    async updateDocumentsWhere(filters, partialUpdates) {
        return (await this.client.apiClient.UpdateWhere({ filters: filters.build().filters, updates: partialUpdates })).body;
    }
    async getDocument(documentId) {
        return (await this.client.apiClient.GetDocument({ document_id: documentId })).body;
    }
    async deleteDocument(documentId) {
        return (await this.client.apiClient.DeleteDocument({ id: documentId })).body;
    }
    async deleteDocuments(documentIds) {
        var _a;
        const filters = (0, _1.QueryBuilder)().match('_id', documentIds);
        return (await this.client.apiClient.DeleteWhere({ filters: (_a = filters.build().filters) !== null && _a !== void 0 ? _a : [] })).body;
    }
    async deleteDocumentsWhere(filters) {
        var _a;
        return (await this.client.apiClient.DeleteWhere({ filters: (_a = filters.build().filters) !== null && _a !== void 0 ? _a : [] })).body;
    }
}
exports.Dataset = Dataset;
